{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AKIJ-mhcF-S",
        "outputId": "1044d3bf-3e06-4e39-85f3-950caca0a5d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m481.3/491.2 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mMounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Install Hugging Face datasets\n",
        "!pip install datasets scikit-learn --quiet\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHinDksfdjbZ"
      },
      "source": [
        "## UPLOAD DATASET TO GOOGLE DRIVE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBMSQ5VqiH_-",
        "outputId": "dd667f8d-33a5-46d4-94fd-2e25d0499c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples: 21069\n",
            "Testing examples: 2341\n",
            "Training set: 10567 cats, 10502 dogs\n",
            "Testing set: 1174 cats, 1167 dogs\n",
            "Saving training images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving train images: 100%|██████████| 21069/21069 [06:34<00:00, 53.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 10567 cats and 10502 dogs in training set\n",
            "Saving testing images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving test images: 100%|██████████| 2341/2341 [00:43<00:00, 53.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 1174 cats and 1167 dogs in test set\n",
            "/content/drive/MyDrive/cats_vs_dogs/train/cats: 10567 images\n",
            "/content/drive/MyDrive/cats_vs_dogs/train/dogs: 10502 images\n",
            "/content/drive/MyDrive/cats_vs_dogs/test/cats: 1174 images\n",
            "/content/drive/MyDrive/cats_vs_dogs/test/dogs: 1167 images\n"
          ]
        }
      ],
      "source": [
        "# Install Hugging Face datasets\n",
        "!pip install datasets scikit-learn --quiet\n",
        "\n",
        "# Import required libraries\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"cats_vs_dogs\")\n",
        "full_dataset = dataset[\"train\"]\n",
        "\n",
        "# Extract labels\n",
        "labels = full_dataset[\"labels\"]\n",
        "\n",
        "# Create stratified train/test indices using scikit-learn\n",
        "train_indices, test_indices = train_test_split(\n",
        "    np.arange(len(full_dataset)),\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "# Create train and test splits\n",
        "train_dataset = full_dataset.select(train_indices)\n",
        "test_dataset = full_dataset.select(test_indices)\n",
        "\n",
        "# Verify the splits\n",
        "print(f\"Training examples: {len(train_dataset)}\")\n",
        "print(f\"Testing examples: {len(test_dataset)}\")\n",
        "\n",
        "# Count class distribution in splits\n",
        "train_cats = sum(1 for example in train_dataset if example[\"labels\"] == 0)\n",
        "train_dogs = sum(1 for example in train_dataset if example[\"labels\"] == 1)\n",
        "test_cats = sum(1 for example in test_dataset if example[\"labels\"] == 0)\n",
        "test_dogs = sum(1 for example in test_dataset if example[\"labels\"] == 1)\n",
        "\n",
        "print(f\"Training set: {train_cats} cats, {train_dogs} dogs\")\n",
        "print(f\"Testing set: {test_cats} cats, {test_dogs} dogs\")\n",
        "\n",
        "# Set up directories\n",
        "save_dir = \"/content/drive/MyDrive/cats_vs_dogs\"\n",
        "\n",
        "# Train folders\n",
        "train_cats_dir = os.path.join(save_dir, \"train\", \"cats\")\n",
        "train_dogs_dir = os.path.join(save_dir, \"train\", \"dogs\")\n",
        "\n",
        "# Test folders\n",
        "test_cats_dir = os.path.join(save_dir, \"test\", \"cats\")\n",
        "test_dogs_dir = os.path.join(save_dir, \"test\", \"dogs\")\n",
        "\n",
        "# Clear existing directories and create new ones\n",
        "for directory in [train_cats_dir, train_dogs_dir, test_cats_dir, test_dogs_dir]:\n",
        "    if os.path.exists(directory):\n",
        "        shutil.rmtree(directory)\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Save training images\n",
        "train_cat_counter = 0\n",
        "train_dog_counter = 0\n",
        "print(\"Saving training images...\")\n",
        "for example in tqdm(train_dataset, desc=\"Saving train images\"):\n",
        "    if example[\"labels\"] == 0:  # Cat\n",
        "        filename = f\"cat_{train_cat_counter}.jpg\"\n",
        "        path = os.path.join(train_cats_dir, filename)\n",
        "        train_cat_counter += 1\n",
        "    else:  # Dog\n",
        "        filename = f\"dog_{train_dog_counter}.jpg\"\n",
        "        path = os.path.join(train_dogs_dir, filename)\n",
        "        train_dog_counter += 1\n",
        "    example[\"image\"].save(path)\n",
        "\n",
        "print(f\"Saved {train_cat_counter} cats and {train_dog_counter} dogs in training set\")\n",
        "\n",
        "# Save testing images\n",
        "test_cat_counter = 0\n",
        "test_dog_counter = 0\n",
        "print(\"Saving testing images...\")\n",
        "for example in tqdm(test_dataset, desc=\"Saving test images\"):\n",
        "    if example[\"labels\"] == 0:  # Cat\n",
        "        filename = f\"cat_{test_cat_counter}.jpg\"\n",
        "        path = os.path.join(test_cats_dir, filename)\n",
        "        test_cat_counter += 1\n",
        "    else:  # Dog\n",
        "        filename = f\"dog_{test_dog_counter}.jpg\"\n",
        "        path = os.path.join(test_dogs_dir, filename)\n",
        "        test_dog_counter += 1\n",
        "    example[\"image\"].save(path)\n",
        "\n",
        "print(f\"Saved {test_cat_counter} cats and {test_dog_counter} dogs in test set\")\n",
        "\n",
        "# Verify that all directories have images\n",
        "for directory in [train_cats_dir, train_dogs_dir, test_cats_dir, test_dogs_dir]:\n",
        "    file_count = len(os.listdir(directory))\n",
        "    print(f\"{directory}: {file_count} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGBEtyNN6MYB"
      },
      "source": [
        "## LOAD DATASET FROM GOOGLE DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dy6uFpis8R6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d06a733-1df2-41dc-dc80-0f6bb82d842b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train cat images: 10567\n",
            "Number of train dog images: 10502\n",
            "Number of test cat images: 1174\n",
            "Number of test dog images: 1167\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Path to your dataset\n",
        "save_dir = \"/content/drive/MyDrive/cats_vs_dogs\"\n",
        "cats_train_dir = os.path.join(save_dir, \"train/cats\")\n",
        "dogs_train_dir = os.path.join(save_dir, \"train/dogs\")\n",
        "cats_test_dir = os.path.join(save_dir, \"test/cats\")\n",
        "dogs_test_dir = os.path.join(save_dir, \"test/dogs\")\n",
        "\n",
        "\n",
        "# Count number of files (images) in each folder\n",
        "num_train_cats = len([name for name in os.listdir(cats_train_dir) if os.path.isfile(os.path.join(cats_train_dir, name))])\n",
        "num_train_dogs = len([name for name in os.listdir(dogs_train_dir) if os.path.isfile(os.path.join(dogs_train_dir, name))])\n",
        "num_test_cats = len([name for name in os.listdir(cats_test_dir) if os.path.isfile(os.path.join(cats_test_dir, name))])\n",
        "num_test_dogs = len([name for name in os.listdir(dogs_test_dir) if os.path.isfile(os.path.join(dogs_test_dir, name))])\n",
        "\n",
        "print(f\"Number of train cat images: {num_train_cats}\")\n",
        "print(f\"Number of train dog images: {num_train_dogs}\")\n",
        "print(f\"Number of test cat images: {num_test_cats}\")\n",
        "print(f\"Number of test dog images: {num_test_dogs}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnlX2AzdiLJm"
      },
      "source": [
        "## Model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kNUxZ26cii-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ef8ae5-1ae7-4f4f-b77c-4601ac4aecbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model=Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(100,100,3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DncU2IboyCal"
      },
      "outputs": [],
      "source": [
        "#Define loss function\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPIjZ_B0Dg2Z"
      },
      "source": [
        "## LOADING DATA to current workspace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GeKom1vEEV33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587e21e2-a121-4edc-bc50-c6677fdece77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset copied to local Colab storage!\n",
            "cats_vs_dogs/\n",
            "  test/\n",
            "    dogs/\n",
            "      dog_123.jpg\n",
            "      dog_588.jpg\n",
            "      dog_543.jpg\n",
            "      dog_994.jpg\n",
            "      dog_875.jpg\n",
            "    cats/\n",
            "      cat_532.jpg\n",
            "      cat_277.jpg\n",
            "      cat_1159.jpg\n",
            "      cat_75.jpg\n",
            "      cat_2.jpg\n",
            "  train/\n",
            "    dogs/\n",
            "      dog_10403.jpg\n",
            "      dog_4148.jpg\n",
            "      dog_3889.jpg\n",
            "      dog_5189.jpg\n",
            "      dog_6599.jpg\n",
            "    cats/\n",
            "      cat_6128.jpg\n",
            "      cat_6834.jpg\n",
            "      cat_5489.jpg\n",
            "      cat_6799.jpg\n",
            "      cat_10041.jpg\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "# Your current dataset path in Drive\n",
        "drive_dataset_path = \"/content/drive/MyDrive/cats_vs_dogs\"\n",
        "\n",
        "# Local dataset path in Colab\n",
        "local_dataset_path = \"/content/cats_vs_dogs\"\n",
        "\n",
        "# If local folder exists already, remove it first to avoid mixing old files\n",
        "if os.path.exists(local_dataset_path):\n",
        "    shutil.rmtree(local_dataset_path)\n",
        "\n",
        "# Now copy the entire dataset from Drive to Colab\n",
        "shutil.copytree(drive_dataset_path, local_dataset_path)\n",
        "\n",
        "print(\"✅ Dataset copied to local Colab storage!\")\n",
        "\n",
        "# Verify structure\n",
        "for root, dirs, files in os.walk(local_dataset_path):\n",
        "    level = root.replace(local_dataset_path, '').count(os.sep)\n",
        "    indent = ' ' * 2 * (level)\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for f in files[:5]:  # Only show first 5 files per folder\n",
        "        print(f\"{subindent}{f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FisBzMX1zLvk"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nndSY40zQfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9286be02-6155-4b52-80ee-0a667a8fdbd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16856 images belonging to 2 classes.\n",
            "Found 4213 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m214/527\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 516ms/step - accuracy: 0.5577 - loss: 0.6934"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set up ImageDataGenerator for training and validation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,         # Normalize pixel values\n",
        "    validation_split=0.2    # 20% of training data for validation\n",
        ")\n",
        "save_dir = \"/content/cats_vs_dogs\"\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(save_dir, \"train\"),\n",
        "    target_size=(100, 100),     # Match your CNN input size\n",
        "    batch_size=32,\n",
        "    class_mode='binary',        # Binary classification (cat vs dog)\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(save_dir, \"train\"),\n",
        "    target_size=(100, 100),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Now fit the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "model_save_path = '/content/cats_vs_dogs_model.h5'\n",
        "model.save(model_save_path)\n",
        "print(f\"✅ Model saved at: {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVFgJCHdQQYd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Plot training/validation accuracy and loss curves with annotations\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(16, 6))\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy', marker='o')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy', marker='x')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    # Annotate best validation accuracy\n",
        "    best_epoch_acc = np.argmax(val_acc)\n",
        "    best_val_acc = val_acc[best_epoch_acc]\n",
        "    plt.scatter(best_epoch_acc, best_val_acc, color='red')\n",
        "    plt.text(best_epoch_acc, best_val_acc + 0.01, f'{best_val_acc:.2f}', ha='center', color='red')\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss', marker='o')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss', marker='x')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    # Annotate minimum validation loss\n",
        "    best_epoch_loss = np.argmin(val_loss)\n",
        "    best_val_loss = val_loss[best_epoch_loss]\n",
        "    plt.scatter(best_epoch_loss, best_val_loss, color='green')\n",
        "    plt.text(best_epoch_loss, best_val_loss + 0.02, f'{best_val_loss:.2f}', ha='center', color='green')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Then just call it:\n",
        "plot_history(history)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}